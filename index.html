<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Multimodal Neurons in Pretrained Text-Only Transformers">
  <meta name="keywords" content="Interpretability, Transformers, Multimodal, NLP">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Multimodal Neurons in Pretrained Text-Only Transformers</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Multimodal Neurons in Pretrained Text-Only Transformers</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://cogconfluence.com">Sarah Schwettmann*</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://nchowdhury.com/">Neil Chowdhury*</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://cyber.harvard.edu/people/sklein">Samuel Klein</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://baulab.info/">David Bau</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://groups.csail.mit.edu/vision/torralbalab/">Antonio Torralba</a><sup>1</sup>
            </span>
          </div>
		
	  * indicates equal contribution.

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>MIT CSAIL</span>
	    <span class="author-block"><sup>2</sup>MIT KFG</span>
            <span class="author-block"><sup>3</sup>Northeastern University</span>
          </div>
		

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="http://www.cogconfluence.com/wp-content/uploads/2023/05/Multimodal_Neurons_4_7_2023.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
		<a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv (coming soon)</span>
             	 </a>   
              </span>
              <!-- Code Link. -->
              <span class="link-block">
              	<a href="" 
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (coming soon)</span>
              	</a>  
              </span>
            
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>
	
<section class="section" style="margin-top: -5px;">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
	<h3 class="title is-4">If a model only learned to read and write, what can its neurons see?</h3>
    </div>
   </div>
</section>
		
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
        <img source src="./static/figures/teaser_placeholder.png" />
      <h2 class="subtitle has-text-centered">
        <span class="coolname">Multimodal Neurons</span> description placeholder text
      </h2>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Large language models demonstrate remarkable flexibility in generalizing representations 
		  learned in a single modality to downstream tasks in modalities unseen during training. We study
		  the case where a single linear projection layer converts unsupervised visual representations 
		  directly into soft prompts for a frozen language model. We show that these “image prompts” are 
		  not themselves decodable into language, but propagate image content to multimodal neurons in 
		  deeper layers of the transformer that convert visual representations into corresponding text
		  representations. We introduce a procedure for identifying multimodal neurons in transformer 
		  MLPs based on their contribution to a crossmodal task, and decoding the concepts they inject 
		  into the model's residual stream. Our finding of multimodal neurons in this setting suggests that 
		  their emergence does not depend on joint visual and language supervision, since they emerge 
		  in a network pretrained only on text. Further, we find that the visual specificity of the language 
		  model neurons is robust to different inputs, and they have a systematic causal effect on model 
		  caption generation.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>
	
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
        <img source src="./static/figures/main_decoding_heatmap.png" />
    </div>
  </div>
</section>
	
	
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
        <img source src="./static/figures/example_units.png" />
    </div>
  </div>
</section>

<footer class="footer">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website adapted from the Nerfies template, which is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            just link back to it in the footer.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>
	
	
	

</body>
</html>
